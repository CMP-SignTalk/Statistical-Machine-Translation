{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the LM classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Handle the unseen and unkown problems.\n",
    "- Vocabs can be derived from the training data with cutoff (unk_cutoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import lm as lm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_corpus ['date be not fetish .', 'result speak for mselves .', 'it should mean that everyone be give equal opportunity .', 'europe have do very great deal work in this field , which be to be welcome .', 'we simply have to build it stage by stage .', 'it be issue proportionality .', 'we be talk about rights , plurality and freedom .', 'that attempt do not succeed , but it do represent precedent for that kind garing .', 'this green paper be important , see as it concern matter that need to be deal with .', 'mr audy ask follow question be you sample sufficient size ?', 'it be up to you to consider and choose outcome you want to see .', 'what can we expect from china ?']\n"
     ]
    }
   ],
   "source": [
    "e_corpus = utils.load_data(\"data/small/aslg.processed.gloss.asl\")\n",
    "print('e_corpus',e_corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabs ['expect', 'with', 'opportunity', 'work', 'you', 'very', 'but', 'outcome', 'mean', 'about', 'garing', 'stage', 'everyone', 'kind', 'and', 'freedom', 'it', 'sufficient', '.', 'by', 'concern', 'paper', 'from', '?', 'follow', '<s>', 'audy', 'great', 'size', 'simply', 'important', 'green', '</s>', 'ask', 'represent', 'result', 'not', 'we', 'this', 'be', 'proportionality', 'fetish', 'up', 'mselves', 'issue', 'date', 'equal', 'have', 'do', 'that', 'should', 'rights', 'mr', 'china', ',', 'need', 'which', 'europe', 'can', 'want', 'in', 'attempt', 'precedent', 'matter', 'choose', 'see', 'talk', 'welcome', 'field', 'speak', 'consider', 'to', 'question', 'plurality', 'as', 'what', 'sample', 'for', 'give', 'succeed', 'deal', 'build']\n",
      "e_corpus [['<s>', 'date', 'be', 'not', 'fetish', '.', '</s>'], ['<s>', 'result', 'speak', 'for', 'mselves', '.', '</s>'], ['<s>', 'it', 'should', 'mean', 'that', 'everyone', 'be', 'give', 'equal', 'opportunity', '.', '</s>'], ['<s>', 'europe', 'have', 'do', 'very', 'great', 'deal', 'work', 'in', 'this', 'field', ',', 'which', 'be', 'to', 'be', 'welcome', '.', '</s>'], ['<s>', 'we', 'simply', 'have', 'to', 'build', 'it', 'stage', 'by', 'stage', '.', '</s>'], ['<s>', 'it', 'be', 'issue', 'proportionality', '.', '</s>'], ['<s>', 'we', 'be', 'talk', 'about', 'rights', ',', 'plurality', 'and', 'freedom', '.', '</s>'], ['<s>', 'that', 'attempt', 'do', 'not', 'succeed', ',', 'but', 'it', 'do', 'represent', 'precedent', 'for', 'that', 'kind', 'garing', '.', '</s>'], ['<s>', 'this', 'green', 'paper', 'be', 'important', ',', 'see', 'as', 'it', 'concern', 'matter', 'that', 'need', 'to', 'be', 'deal', 'with', '.', '</s>'], ['<s>', 'mr', 'audy', 'ask', 'follow', 'question', 'be', 'you', 'sample', 'sufficient', 'size', '?', '</s>'], ['<s>', 'it', 'be', 'up', 'to', 'you', 'to', 'consider', 'and', 'choose', 'outcome', 'you', 'want', 'to', 'see', '.', '</s>'], ['<s>', 'what', 'can', 'we', 'expect', 'from', 'china', '?', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "e_vocabs, e_corpus = utils.preprocess(e_corpus)\n",
    "print('vocabs',e_vocabs)\n",
    "print('e_corpus',e_corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Language Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability 0.046610169491525424\n",
      "sentence_probability 6.0182371912008816e-12\n",
      "log_probability -3.0659365322272394\n",
      "log_sentence_probability -25.83622672487146\n"
     ]
    }
   ],
   "source": [
    "unigram_lm = lm.Unigram(e_vocabs, e_corpus)\n",
    "unigram_lm.train()\n",
    "probability = unigram_lm.calc_probability('be')\n",
    "print('probability',probability)\n",
    "sentence_probability = unigram_lm.calc_sentence_probability('date be not fetish .')\n",
    "print('sentence_probability',sentence_probability)\n",
    "log_probability = unigram_lm.calc_log_probability('be')\n",
    "print('log_probability',log_probability)\n",
    "log_sentence_probability = unigram_lm.calc_log_sentence_probability('date be not fetish .')\n",
    "print('log_sentence_probability',log_sentence_probability)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the unseen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability 0.00423728813559322\n"
     ]
    }
   ],
   "source": [
    "probability = unigram_lm.calc_probability('cmp')\n",
    "print('probability',probability)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability 0.021505376344086023\n",
      "sentence_probability 7.142917979414252e-10\n",
      "log_probability -3.8394523125933104\n",
      "log_sentence_probability -21.059729556485898\n"
     ]
    }
   ],
   "source": [
    "bigram_lm = lm.Bigram(e_vocabs, e_corpus)\n",
    "bigram_lm.train()\n",
    "probability = bigram_lm.calc_probability('be','not')\n",
    "print('probability',probability)\n",
    "sentence_probability = bigram_lm.calc_sentence_probability('date be not fetish .')\n",
    "print('sentence_probability',sentence_probability)\n",
    "log_probability = bigram_lm.calc_log_probability('be','not')\n",
    "print('log_probability',log_probability)\n",
    "log_sentence_probability = bigram_lm.calc_log_sentence_probability('date be not fetish .')\n",
    "print('log_sentence_probability',log_sentence_probability)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability 0.023809523809523808\n",
      "sentence_probability 7.651622719418543e-09\n",
      "log_probability -3.7376696182833684\n",
      "log_sentence_probability -18.68834809141684\n"
     ]
    }
   ],
   "source": [
    "trigram_lm = lm.Trigram(e_vocabs, e_corpus)\n",
    "trigram_lm.train()\n",
    "probability = trigram_lm.calc_probability('be','not','fetish')\n",
    "print('probability',probability)\n",
    "sentence_probability = trigram_lm.calc_sentence_probability('date be not fetish .')\n",
    "print('sentence_probability',sentence_probability)\n",
    "log_probability = trigram_lm.calc_log_probability('be','not','fetish')\n",
    "print('log_probability',log_probability)\n",
    "log_sentence_probability = trigram_lm.calc_log_sentence_probability('date be not fetish .')\n",
    "print('log_sentence_probability',log_sentence_probability)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_probability 0.023809523809523808\n",
      "log_sentence_probability -17.597517215733067\n"
     ]
    }
   ],
   "source": [
    "ilm = lm.LM(e_vocabs, e_corpus)\n",
    "ilm.train()\n",
    "sentence_probability = ilm.calc_sentence_probability('date be not fetish .')\n",
    "print('sentence_probability',probability)\n",
    "log_sentence_probability = ilm.calc_log_sentence_probability('date be not fetish .')\n",
    "print('log_sentence_probability',log_sentence_probability)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the language models\n",
    "utils.save_model(unigram_lm, \"models/unigram_model.pkl\")\n",
    "utils.save_model(bigram_lm, \"models/bigram_model.pkl\")\n",
    "utils.save_model(trigram_lm, \"models/trigram_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
